{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OSM 2018 Economics \n",
    "## Problem Set 5\n",
    "### 07.23.2018 \n",
    "### Yung-Hsu Tsui*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 Health Claims\n",
    "#### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "clms.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-15ab9726195e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'notebook'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clms.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#importing health claims data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Health Claims'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    614\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    615\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: clms.txt not found."
     ]
    }
   ],
   "source": [
    "# Importing the package\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats  as sts\n",
    "from pandas import DataFrame, Series\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "pts = np.loadtxt('clms.txt') #importing health claims data\n",
    "df1= DataFrame(pts, columns=['Health Claims'])\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting First Historgram\n",
    "count, bins, ignored = plt.hist(pts, 1000, edgecolor='black', normed=True)\n",
    "plt.title('Fictitious Health Claims ', fontsize=20)\n",
    "plt.xlabel('Expenditures')\n",
    "plt.ylabel('Percent of Observation')\n",
    "plt.xlim([0, 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Second Historgram\n",
    "n=100\n",
    "weights = np.empty_like(pts)\n",
    "weights.fill((len(pts[pts<=800])/len(pts)) * n / (800-0) / pts.size)\n",
    "count, bins, ignored = plt.hist(pts, n, edgecolor='blue',weights=weights, range=(0,800))\n",
    "plt.title('Fictitious Health Claims Less than 800', fontsize=20)\n",
    "plt.xlabel('Expenditures')\n",
    "plt.ylabel('Percent of Observation')\n",
    "plt.xlim([-10, 810])\n",
    "plt.ylim([0,0.006])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I prefer the latter one. The reason is because the latter one focuses on the information that I desire the most. What I care about is the distributio for most of people, whose expdenditures are mostly below $800. \n",
    "\n",
    "#### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the package\n",
    "# Gamma Distribution\n",
    "from scipy.special import gamma\n",
    "import scipy.special as sps\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Functions\n",
    "def gamma_pdf(xvals,alpha,beta):\n",
    "    pdf = xvals**(alpha-1) * (np.exp(-xvals/beta)) / (sps.gamma(alpha) * beta**alpha) \n",
    "    return pdf\n",
    "\n",
    "def log_lik_gamma(xvals, a, b):\n",
    "    pdf_vals = gamma_pdf(xvals, a , b)\n",
    "    ln_pdf_vals = np.log(pdf_vals)\n",
    "    log_lik_val = ln_pdf_vals.sum()\n",
    "    return log_lik_val\n",
    "\n",
    "def crit_gamma(params, args):\n",
    "    alpha, beta = params\n",
    "    xvals = args\n",
    "    log_lik_val = log_lik_gamma(xvals,alpha,beta)\n",
    "    neg_log_lik_val = -log_lik_val\n",
    "    return neg_log_lik_val\n",
    "\n",
    "#Settings\n",
    "mu = np.mean(pts)\n",
    "var = np.var(pts)\n",
    "beta = var/mu\n",
    "alpha = mu/beta\n",
    "m = 1\n",
    "\n",
    "#Initial Guesses\n",
    "alpha_init = alpha\n",
    "beta_init = beta -20000\n",
    "params1_init = np.array([alpha_init, beta_init])\n",
    "mle_args = pts\n",
    "\n",
    "#Plot\n",
    "%matplotlib notebook\n",
    "n=100\n",
    "weights = np.empty_like(pts)\n",
    "weights.fill((len(pts[pts<=800])/len(pts)) * n / (800-0) / pts.size)\n",
    "count, bins, ignored = plt.hist(pts, n, edgecolor='blue',weights=weights, range=(0,800))\n",
    "plt.title('Health Claims and Gamma Estimation', fontsize=20)\n",
    "plt.xlabel('Expenditures')\n",
    "plt.ylabel('Percent of Observation')\n",
    "plt.xlim([-10, 810])\n",
    "plt.ylim([0,0.006])\n",
    "dist_pts = np.linspace(0, 800, 1000)\n",
    "plt.plot(dist_pts, gamma_pdf(dist_pts, alpha=alpha, beta=beta),linewidth=2, color='r',label='1: Gamma Estimation')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "#Log-likelihood\n",
    "print('Log-likelihood 1: ', log_lik_gamma(pts, alpha, beta))\n",
    "\n",
    "#MLE-result\n",
    "results1 = opt.minimize(crit_gamma, params1_init, args=(mle_args), method='L-BFGS-B', bounds=((1e-10, None),(1e-10, None)))\n",
    "alpha1_MLE, beta1_MLE = results1.x\n",
    "print('alpha_MLE=', alpha1_MLE, ' beta_MLE=', beta1_MLE)\n",
    "results1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Package\n",
    "#Generalized Gamma Distribution\n",
    "from scipy.special import gamma\n",
    "import scipy.special as sps\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Functions\n",
    "def gengamma_pdf(xvals,a,b,m):\n",
    "    pdf2  = (m*(xvals**(a-1))*(np.exp(-(xvals/b)**m)))/((b**a)*sps.gamma(a/m))\n",
    "    return pdf2\n",
    "\n",
    "def log_lik_gengamma(xvals, alpha, beta, m):\n",
    "    pdf_vals = gengamma_pdf(xvals, a=alpha, b=beta, m=m)\n",
    "    ln_pdf_vals = np.log(pdf_vals)\n",
    "    log_lik_val = ln_pdf_vals.sum()\n",
    "    return log_lik_val\n",
    "\n",
    "def crit_gengamma(params, args):\n",
    "    alpha, beta, m = params\n",
    "    xvals = args\n",
    "    log_lik_val = log_lik_gengamma(xvals,alpha, beta,m)\n",
    "    neg_log_lik_val = -log_lik_val\n",
    "    return neg_log_lik_val\n",
    "\n",
    "#Initial Guesses from Part(b)\n",
    "alpha_init = alpha1_MLE\n",
    "beta_init = beta1_MLE\n",
    "params2_init = np.array([alpha_init, beta_init,m])\n",
    "mle_args = pts\n",
    "m=1\n",
    "\n",
    "#Log-likelihood\n",
    "print('Log-likelihood 2: ', log_lik_gengamma(pts, alpha_init, beta_init,m))\n",
    "\n",
    "#MLE-result\n",
    "results2 = opt.minimize(crit_gengamma, params2_init, args=(mle_args), method='L-BFGS-B',bounds=((1e-10, None),(1e-10, None),(1e-10, None)))\n",
    "alpha2_MLE, beta2_MLE, m2_MLE = results2.x\n",
    "print('alpha_MLE=', alpha2_MLE, ' beta_MLE=', beta2_MLE, 'm_MLE=', m2_MLE)\n",
    "\n",
    "#Plot\n",
    "%matplotlib notebook\n",
    "n=100\n",
    "weights = np.empty_like(pts)\n",
    "weights.fill((len(pts[pts<=800])/len(pts)) * n / (800-0) / pts.size)\n",
    "count, bins, ignored = plt.hist(pts, n, edgecolor='blue',weights=weights, range=(0,800))\n",
    "plt.title('Health Claims and General Gamma Estimation', fontsize=20)\n",
    "plt.xlabel('Expenditures')\n",
    "plt.ylabel('Percent of Observation')\n",
    "plt.xlim([-10, 810])\n",
    "plt.ylim([0,0.006])\n",
    "dist_pts = np.linspace(0, 800, 1000)\n",
    "plt.plot(dist_pts, gengamma_pdf(dist_pts, a=alpha2_MLE, b=beta2_MLE, m=m_MLE),linewidth=2, color='g',label='1: Gengamma Estimation')\n",
    "plt.legend(loc='upper right')\n",
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 1(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.d\n",
    "##Generalized Beta 2 Distribution\n",
    "from scipy.special import beta\n",
    "import scipy.special as sps\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Functions\n",
    "def gb2_pdf(xvals,a,b,p,q):\n",
    "    pdf3 = a*xvals**(a*p-1)/(b**(a*p)*(1+(xvals/b)**a)**(p+q)*sps.beta(p,q))\n",
    "    return pdf3\n",
    "\n",
    "def log_lik_gb2(xvals, a, b, p, q):\n",
    "    pdf_vals = gb2_pdf(xvals, a, b, p, q)\n",
    "    log_pdf_vals = np.log(pdf_vals)\n",
    "    log_lik_val = log_pdf_vals.sum()\n",
    "    return log_lik_val\n",
    "\n",
    "def crit_gb2(params, args):\n",
    "    a, b, p, q = params\n",
    "    xvals = args\n",
    "    log_lik_val = log_lik_gb2(xvals, a, b, p, q)\n",
    "    neg_log_lik_val = -log_lik_val\n",
    "    return neg_log_lik_val\n",
    "\n",
    "#Initial Guesses from Part(c)\n",
    "q=10000\n",
    "a_init = m2_MLE\n",
    "b_init = beta2_MLE*q**(1/m2_MLE) \n",
    "p_init = alpha2_MLE/m2_MLE \n",
    "params3_init = np.array([a_init, b_init,p_init,q])\n",
    "mle_args = pts\n",
    "\n",
    "#Log-likelihood\n",
    "print('Log-likelihood 3: ', log_lik_gb2(pts, a= a_init, b=b_init,p=p_init,q=q))\n",
    "\n",
    "#MLE-result\n",
    "results3 = opt.minimize(crit_gb2, params3_init, args=(mle_args), method='L-BFGS-B',bounds=((1e-10, None),(1e-10, None),(1e-10, None),(1e-10, None)))\n",
    "a_MLE, b_MLE, p_MLE, q_MLE = results3.x\n",
    "print('a_MLE=', a_MLE, ' b_MLE=', b_MLE, 'p_MLE=', p_MLE, 'q_MLE=',q_MLE)\n",
    "\n",
    "#Plot\n",
    "%matplotlib notebook\n",
    "n=100\n",
    "weights = np.empty_like(pts)\n",
    "weights.fill((len(pts[pts<=800])/len(pts)) * n / (800-0) / pts.size)\n",
    "count, bins, ignored = plt.hist(pts, n, edgecolor='blue',weights=weights, range=(0,800))\n",
    "plt.title('Health Claims and GB2 Estimation', fontsize=20)\n",
    "plt.xlabel('Expenditures')\n",
    "plt.ylabel('Percent of Observation')\n",
    "plt.xlim([-10, 810])\n",
    "plt.ylim([0,0.006])\n",
    "dist_pts = np.linspace(0, 800, 1000)\n",
    "plt.plot(dist_pts, gb2_pdf(dist_pts, a=a_MLE, b=b_MLE , p=p_MLE,q=q_MLE),linewidth=2, color='y',label='1: GB2 Estimation')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "results3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.f\n",
    "# Probability Calculation\n",
    "from scipy.integrate import quad\n",
    "def integrand1(x):\n",
    "    return gb2_pdf(x, a=a_MLE, b=b_MLE, p=p_MLE, q=q_MLE)\n",
    "def integrand2(x):\n",
    "    return gamma_pdf(x, alpha=alpha1_MLE, beta=beta1_MLE)\n",
    "prob1 = quad(integrand1,0, 1000)\n",
    "prob2 = quad(integrand2,0, 1000)\n",
    "print('Probability above $1000 GB2 = ', 1-prob1[0])\n",
    "print('Probability above $1000 Gamma = ', 1-prob2[0])\n",
    "#From the results we obtain, it is not less likely to have a health claim over $1,000 with GB2 distribution.\n",
    "#The probability of having claims over $1,000 increases when we use Gamma distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "clms.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a2bbbdd13387>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clms.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#importing health claims data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Health Claims'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    614\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    615\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: clms.txt not found."
     ]
    }
   ],
   "source": [
    "#1.a_1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "pts = np.loadtxt('clms.txt') #importing health claims data\n",
    "df1= DataFrame(pts, columns=['Health Claims'])\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'B' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-31836aeaab22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'B' is not defined"
     ]
    }
   ],
   "source": [
    "#1.a_2\n",
    "import numpy as np\n",
    "import scipy.stats as sts\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "count, bins, ignored = plt.hist(pts, 1000, edgecolor='black', normed=True)\n",
    "plt.title('Fictitious Health Claims ', fontsize=20)\n",
    "plt.xlabel('Expenditures')\n",
    "plt.ylabel('Percent of Observation')\n",
    "plt.xlim([0, 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.a_3\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "n=100\n",
    "weights = np.empty_like(pts)\n",
    "weights.fill((len(pts[pts<=800])/len(pts)) * n / (800-0) / pts.size)\n",
    "count, bins, ignored = plt.hist(pts, n, edgecolor='blue',weights=weights, range=(0,800))\n",
    "plt.title('Fictitious Health Claims Less than 800', fontsize=20)\n",
    "plt.xlabel('Expenditures')\n",
    "plt.ylabel('Percent of Observation')\n",
    "plt.xlim([-10, 810])\n",
    "plt.ylim([0,0.006])\n",
    "#The reason that I might prefer the latter one is because the latter one focuses on the information that I desire the most.\n",
    "#What I care about is the distributio for most of people, whose expdenditures are mostly below $800.\n",
    "#I might not be interested to study for the extreme cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.b\n",
    "##Gamma Distribution\n",
    "from scipy.special import gamma\n",
    "import scipy.special as sps\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Functions\n",
    "def gamma_pdf(xvals,alpha,beta):\n",
    "    pdf = xvals**(alpha-1) * (np.exp(-xvals/beta)) / (sps.gamma(alpha) * beta**alpha) \n",
    "    return pdf\n",
    "\n",
    "def log_lik_gamma(xvals, a, b):\n",
    "    pdf_vals = gamma_pdf(xvals, a , b)\n",
    "    ln_pdf_vals = np.log(pdf_vals)\n",
    "    log_lik_val = ln_pdf_vals.sum()\n",
    "    return log_lik_val\n",
    "\n",
    "def crit_gamma(params, args):\n",
    "    alpha, beta = params\n",
    "    xvals = args\n",
    "    log_lik_val = log_lik_gamma(xvals,alpha,beta)\n",
    "    neg_log_lik_val = -log_lik_val\n",
    "    return neg_log_lik_val\n",
    "\n",
    "#Settings\n",
    "mu = np.mean(pts)\n",
    "var = np.var(pts)\n",
    "beta = var/mu\n",
    "alpha = mu/beta\n",
    "m = 1\n",
    "\n",
    "#Initial Guesses\n",
    "alpha_init = alpha\n",
    "beta_init = beta -20000\n",
    "params1_init = np.array([alpha_init, beta_init])\n",
    "mle_args = pts\n",
    "\n",
    "#Plot\n",
    "%matplotlib notebook\n",
    "n=100\n",
    "weights = np.empty_like(pts)\n",
    "weights.fill((len(pts[pts<=800])/len(pts)) * n / (800-0) / pts.size)\n",
    "count, bins, ignored = plt.hist(pts, n, edgecolor='blue',weights=weights, range=(0,800))\n",
    "plt.title('Health Claims and Gamma Estimation', fontsize=20)\n",
    "plt.xlabel('Expenditures')\n",
    "plt.ylabel('Percent of Observation')\n",
    "plt.xlim([-10, 810])\n",
    "plt.ylim([0,0.006])\n",
    "dist_pts = np.linspace(0, 800, 1000)\n",
    "plt.plot(dist_pts, gamma_pdf(dist_pts, alpha=alpha, beta=beta),linewidth=2, color='r',label='1: Gamma Estimation')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "#Log-likelihood\n",
    "print('Log-likelihood 1: ', log_lik_gamma(pts, alpha, beta))\n",
    "\n",
    "#MLE-result\n",
    "results1 = opt.minimize(crit_gamma, params1_init, args=(mle_args), method='L-BFGS-B', bounds=((1e-10, None),(1e-10, None)))\n",
    "alpha1_MLE, beta1_MLE = results1.x\n",
    "print('alpha_MLE=', alpha1_MLE, ' beta_MLE=', beta1_MLE)\n",
    "results1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.c\n",
    "##Generalized Gamma Distribution\n",
    "from scipy.special import gamma\n",
    "import scipy.special as sps\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Functions\n",
    "def gengamma_pdf(xvals,a,b,m):\n",
    "    pdf2  = (m*(xvals**(a-1))*(np.exp(-(xvals/b)**m)))/((b**a)*sps.gamma(a/m))\n",
    "    return pdf2\n",
    "\n",
    "def log_lik_gengamma(xvals, alpha, beta, m):\n",
    "    pdf_vals = gengamma_pdf(xvals, a=alpha, b=beta, m=m)\n",
    "    ln_pdf_vals = np.log(pdf_vals)\n",
    "    log_lik_val = ln_pdf_vals.sum()\n",
    "    return log_lik_val\n",
    "\n",
    "def crit_gengamma(params, args):\n",
    "    alpha, beta, m = params\n",
    "    xvals = args\n",
    "    log_lik_val = log_lik_gengamma(xvals,alpha, beta,m)\n",
    "    neg_log_lik_val = -log_lik_val\n",
    "    return neg_log_lik_val\n",
    "\n",
    "#Initial Guesses from Part(b)\n",
    "alpha_init = alpha1_MLE\n",
    "beta_init = beta1_MLE\n",
    "params2_init = np.array([alpha_init, beta_init,m])\n",
    "mle_args = pts\n",
    "m=1\n",
    "\n",
    "#Log-likelihood\n",
    "print('Log-likelihood 2: ', log_lik_gengamma(pts, alpha_init, beta_init,m))\n",
    "\n",
    "#MLE-result\n",
    "results2 = opt.minimize(crit_gengamma, params2_init, args=(mle_args), method='L-BFGS-B',bounds=((1e-10, None),(1e-10, None),(1e-10, None)))\n",
    "alpha2_MLE, beta2_MLE, m2_MLE = results2.x\n",
    "print('alpha_MLE=', alpha2_MLE, ' beta_MLE=', beta2_MLE, 'm_MLE=', m2_MLE)\n",
    "\n",
    "#Plot\n",
    "%matplotlib notebook\n",
    "n=100\n",
    "weights = np.empty_like(pts)\n",
    "weights.fill((len(pts[pts<=800])/len(pts)) * n / (800-0) / pts.size)\n",
    "count, bins, ignored = plt.hist(pts, n, edgecolor='blue',weights=weights, range=(0,800))\n",
    "plt.title('Health Claims and General Gamma Estimation', fontsize=20)\n",
    "plt.xlabel('Expenditures')\n",
    "plt.ylabel('Percent of Observation')\n",
    "plt.xlim([-10, 810])\n",
    "plt.ylim([0,0.006])\n",
    "dist_pts = np.linspace(0, 800, 1000)\n",
    "plt.plot(dist_pts, gengamma_pdf(dist_pts, a=alpha2_MLE, b=beta2_MLE, m=m_MLE),linewidth=2, color='g',label='1: Gengamma Estimation')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.d\n",
    "##Generalized Beta 2 Distribution\n",
    "from scipy.special import beta\n",
    "import scipy.special as sps\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Functions\n",
    "def gb2_pdf(xvals,a,b,p,q):\n",
    "    pdf3 = a*xvals**(a*p-1)/(b**(a*p)*(1+(xvals/b)**a)**(p+q)*sps.beta(p,q))\n",
    "    return pdf3\n",
    "\n",
    "def log_lik_gb2(xvals, a, b, p, q):\n",
    "    pdf_vals = gb2_pdf(xvals, a, b, p, q)\n",
    "    log_pdf_vals = np.log(pdf_vals)\n",
    "    log_lik_val = log_pdf_vals.sum()\n",
    "    return log_lik_val\n",
    "\n",
    "def crit_gb2(params, args):\n",
    "    a, b, p, q = params\n",
    "    xvals = args\n",
    "    log_lik_val = log_lik_gb2(xvals, a, b, p, q)\n",
    "    neg_log_lik_val = -log_lik_val\n",
    "    return neg_log_lik_val\n",
    "\n",
    "#Initial Guesses from Part(c)\n",
    "q=10000\n",
    "a_init = m2_MLE\n",
    "b_init = beta2_MLE*q**(1/m2_MLE) \n",
    "p_init = alpha2_MLE/m2_MLE \n",
    "params3_init = np.array([a_init, b_init,p_init,q])\n",
    "mle_args = pts\n",
    "\n",
    "#Log-likelihood\n",
    "print('Log-likelihood 3: ', log_lik_gb2(pts, a= a_init, b=b_init,p=p_init,q=q))\n",
    "\n",
    "#MLE-result\n",
    "results3 = opt.minimize(crit_gb2, params3_init, args=(mle_args), method='L-BFGS-B',bounds=((1e-10, None),(1e-10, None),(1e-10, None),(1e-10, None)))\n",
    "a_MLE, b_MLE, p_MLE, q_MLE = results3.x\n",
    "print('a_MLE=', a_MLE, ' b_MLE=', b_MLE, 'p_MLE=', p_MLE, 'q_MLE=',q_MLE)\n",
    "\n",
    "#Plot\n",
    "%matplotlib notebook\n",
    "n=100\n",
    "weights = np.empty_like(pts)\n",
    "weights.fill((len(pts[pts<=800])/len(pts)) * n / (800-0) / pts.size)\n",
    "count, bins, ignored = plt.hist(pts, n, edgecolor='blue',weights=weights, range=(0,800))\n",
    "plt.title('Health Claims and GB2 Estimation', fontsize=20)\n",
    "plt.xlabel('Expenditures')\n",
    "plt.ylabel('Percent of Observation')\n",
    "plt.xlim([-10, 810])\n",
    "plt.ylim([0,0.006])\n",
    "dist_pts = np.linspace(0, 800, 1000)\n",
    "plt.plot(dist_pts, gb2_pdf(dist_pts, a=a_MLE, b=b_MLE , p=p_MLE,q=q_MLE),linewidth=2, color='y',label='1: GB2 Estimation')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "results3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.e\n",
    "## Likelihood Ratio Tests\n",
    "lrgamma = 2 * (log_lik_gb2(pts, a=a_MLE, b=b_MLE , p=p_MLE,q=q_MLE) - log_lik_gamma(pts, a=alpha2_MLE, b=beta2_MLE))\n",
    "lrgengamma = 2 * (log_lik_gb2(pts, a=a_MLE, b=b_MLE , p=p_MLE,q=q_MLE) - log_lik_gengamma(pts, alpha=alpha2_MLE, beta=beta2_MLE,m=1))\n",
    "print('Likelihood Ratio for Gamma:', lrgamma)\n",
    "print('Likelihood Ratio for Generalized Gamma:', lrgengamma)\n",
    "\n",
    "#1.f\n",
    "# Probability Calculation\n",
    "from scipy.integrate import quad\n",
    "def integrand1(x):\n",
    "    return gb2_pdf(x, a=a_MLE, b=b_MLE, p=p_MLE, q=q_MLE)\n",
    "def integrand2(x):\n",
    "    return gamma_pdf(x, alpha=alpha1_MLE, beta=beta1_MLE)\n",
    "prob1 = quad(integrand1,0, 1000)\n",
    "prob2 = quad(integrand2,0, 1000)\n",
    "print('Probability above $1000 GB2 = ', 1-prob1[0])\n",
    "print('Probability above $1000 Gamma = ', 1-prob2[0])\n",
    "#From the results we obtain, it is not less likely to have a health claim over $1,000 with GB2 distribution.\n",
    "#The probability of having claims over $1,000 increases when we use Gamma distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.a_1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "pts = np.loadtxt('usincmoms.txt')\n",
    "df= DataFrame(pts, columns=['Percentage','Income'])\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.a_2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "height_1=np.append(pts[:40,0],[pts[40,0]/10,pts[41,0]/20,0])\n",
    "#Value of 41st bar is divided by 10.\n",
    "#Value of 42nd bar is divided by 20\n",
    "N=len(pts)\n",
    "plt.figure()\n",
    "tick_1=np.append(np.array(pts[:40,1]/1000-2.5),[200,250,350])\n",
    "width_1=np.append(np.linspace(2.9,2.9,40),[2.9*10,2.9*20,0])\n",
    "ypos_1=np.append(np.linspace(0,123,41),[152,210])\n",
    "plt.bar(ypos_1,height=height_1,width=width_1,edgecolor='blue',align='edge') \n",
    "plt.title('US Income Distribution', fontsize=20)\n",
    "plt.xlabel('House Hold Income in thousand dollars')\n",
    "plt.ylabel('Percentage (%)')\n",
    "plt.xticks(ypos_1,tick_1,fontsize=5.5, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.b_1\n",
    "import scipy.optimize as opt\n",
    "import scipy.integrate as intgr\n",
    "import scipy.stats as sts\n",
    "tick2 = np.append(np.array(pts[:40,1]/1000+2.5),[250,350])\n",
    "tick3 = np.append(np.array(pts[:40,1]/1000-2.5),[200,250])\n",
    "\n",
    "def model_moment(mu,sig):\n",
    "    pb1 = sts.lognorm.cdf(tick2, sig, scale = np.exp(mu))\n",
    "    pb2 = sts.lognorm.cdf(tick3, sig, scale = np.exp(mu))\n",
    "    return pb1 - pb2\n",
    "\n",
    "def err_vec(xvals, mu, sigma):\n",
    "    data = xvals\n",
    "    model = model_moment(mu,sigma)\n",
    "    err_vec = data - model\n",
    "    return err_vec\n",
    "\n",
    "def criterion(params, *args):\n",
    "    mu, sig = params\n",
    "    xvals, W = args\n",
    "    err = err_vec(xvals, mu, sig)\n",
    "    crit_val = err.T @ W @ err\n",
    "    return crit_val\n",
    "\n",
    "mu_init = np.log(pts[:,1].mean())\n",
    "sig_init = np.log(pts[:,1].std())\n",
    "params_init = np.array([mu_init, sig_init])\n",
    "W = np.diag(pts[:,0])\n",
    "gmm_args = (pts[:,1], W)\n",
    "\n",
    "result = opt.minimize(criterion, params_init, args = (gmm_args), method = 'L-BFGS-B', bounds = ((None,None),(1e-10,None)))\n",
    "mu_GMM1, sig_GMM1 = result.x\n",
    "\n",
    "\n",
    "mean_data=pts[:,1].mean()\n",
    "sig_data = pts[:,1].std()\n",
    "pdf = model_moment(mu_GMM1, sig_GMM1)\n",
    "err1 = err_vec(pts[:,1], mu_GMM1, sig_GMM1)\n",
    "\n",
    "print(result)\n",
    "print('Mean of points =', mean_data, ', STD of points =', sig_data)\n",
    "print('Error vector=', err1)\n",
    "print('mu_GMM1=', mu_GMM1, ' sig_GMM1=', sig_GMM1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.b_2\n",
    "plt.figure()\n",
    "aaa=pts[0:42,1]/1000\n",
    "bbb=np.append(pts[0:40,0]/5,[pts[40,0]/50,pts[41,0]/100])\n",
    "ccc=np.append(np.linspace(5,5,40),[5*10,5*20])\n",
    "data = np.append(pts[0:40,1]/1000, [200,250,300,350])\n",
    "plt.bar(aaa, bbb, width =ccc , align = 'center', edgecolor='blue')\n",
    "plt.plot(data, sts.lognorm.pdf(data, sig_GMM1, scale = np.exp(mu_GMM1)), color = 'r', linewidth = 2, label = 'LN')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.c_1\n",
    "def model_moment2(alpha,beta):\n",
    "    pb1 = sts.gamma.cdf(tick2, alpha, scale = beta)\n",
    "    pb2 = sts.gamma.cdf(tick3, alpha, scale = beta)\n",
    "    return pb1-pb2\n",
    "\n",
    "def err_vec2(xvals, alpha, beta):\n",
    "    data = xvals\n",
    "    model = model_moment2(alpha,beta)\n",
    "    err_vec = data - model\n",
    "    return err_vec\n",
    "\n",
    "def criterion2(params, *args):\n",
    "    alpha, beta = params\n",
    "    xvals, W = args\n",
    "    err = err_vec2(xvals, alpha, beta)\n",
    "    crit_val = err.T @ W @ err\n",
    "    return crit_val\n",
    "\n",
    "alpha2_init = 3\n",
    "beta2_init = 20\n",
    "params2_init = np.array([alpha2_init, beta2_init])\n",
    "W = np.diag(pts[:,0])\n",
    "gmm_args = (pts[:,1], W)\n",
    "\n",
    "result2 = opt.minimize(criterion2, params2_init, args = (gmm_args), method = 'L-BFGS-B', bounds = ((1e-10,None),(1e-10,None)))\n",
    "alpha_gmm2, beta_gmm2= result2.x\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.c_2\n",
    "plt.figure()\n",
    "aaa=pts[0:42,1]/1000\n",
    "bbb=np.append(pts[0:40,0]/5,[pts[40,0]/50,pts[41,0]/100])\n",
    "ccc=np.append(np.linspace(5,5,40),[5*10,5*20])\n",
    "data = np.append(pts[0:40,1]/1000, [200,250,300,350])\n",
    "plt.bar(aaa, bbb, width =ccc , align = 'center', edgecolor='blue')\n",
    "plt.plot(data, sts.gamma.pdf(data, alpha_gmm2, scale =beta_gmm2), color = 'g', linewidth = 2, label = 'GA')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.d_1\n",
    "plt.figure()\n",
    "aaa=pts[0:42,1]/1000\n",
    "bbb=np.append(pts[0:40,0]/5,[pts[40,0]/50,pts[41,0]/100])\n",
    "ccc=np.append(np.linspace(5,5,40),[5*10,5*20])\n",
    "data = np.append(pts[0:40,1]/1000, [200,250,300,350])\n",
    "plt.bar(aaa, bbb, width =ccc , align = 'center', edgecolor='blue')\n",
    "plt.plot(data, sts.lognorm.pdf(data, sig_GMM1, scale = np.exp(mu_GMM1)), color = 'r', linewidth = 2, label = 'LN')\n",
    "plt.plot(data, sts.gamma.pdf(data, alpha_gmm2, scale =beta_gmm2), color = 'g', linewidth = 2, label = 'GA')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.d_2 \n",
    "obj_val1 = result.fun\n",
    "obj_val2 = result2.fun\n",
    "print('Minimized Lognormal Objective =', obj_val1)\n",
    "print('Minimized Gamma Objective =', obj_val2)\n",
    "#The most precise way I guess is to compare their objective functions.\n",
    "#From the graph and the test results shown above, Gamma Distribution fits the data better than Lognormal Distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.e_1\n",
    "#First Step W\n",
    "params3_init=[alpha_gmm2,beta_gmm2]\n",
    "WI = np.identity(pts[:,1].shape[0])\n",
    "gmm2s_args = (pts[:,1], WI)\n",
    "\n",
    "result3 = opt.minimize(criterion2, params3_init, args = gmm2s_args, method = 'L-BFGS-B', bounds = ((1e-10,None),(1e-10,None)))\n",
    "alpha_1, beta_1 = result3.x\n",
    "err_vec3 = np.reshape(err_vec2(pts[:,1], alpha_1, beta_1),(42,1))\n",
    "omega = (err_vec3 @ err_vec3.T) / pts[:,1].shape[0] \n",
    "\n",
    "#Second Step W\n",
    "W2S = np.linalg.pinv(omega)\n",
    "gmm2s2_args = (pts[:,1], W2S)\n",
    "params4_init = np.array([alpha_1, beta_1])\n",
    "result4 = opt.minimize(criterion2, params4_init, args = gmm2s2_args, method = 'L-BFGS-B', bounds = ((1e-10,None),(1e-10,None)), tol = 1e-10)\n",
    "alpha_2, beta_2 = result4.x\n",
    "print('Estimation Result')\n",
    "print('')\n",
    "print(result4)\n",
    "\n",
    "#1.e_2\n",
    "obj_val3 = result2.fun\n",
    "obj_val4 = result4.fun\n",
    "print('Minimized Gamma Objective =', obj_val3)\n",
    "print('Minimized Gamma with 2-Step Objective =', obj_val4)\n",
    "#Yes, alpha and beta change quite a bit. From (3.99, 19.90) to (10.37, 23.26).\n",
    "#I compare the difference by comparing the number of their repective objective functions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Brock and Mirman(1972) by GMM\n",
    "pts2 = np.loadtxt('MacroSeries.txt', delimiter = ',')\n",
    "\n",
    "def z_1(alpha, xvals):\n",
    "    z = np.log(xvals[:,3]/(alpha*xvals[:,1]**(alpha-1)))\n",
    "    return z\n",
    "\n",
    "#Moment Conditions\n",
    "def data_moment2(alpha, beta, rho, mu, xvals):\n",
    "    z = z_1(alpha, xvals)\n",
    "    z_t = z[1:100]\n",
    "    z_t_1 = z[0:99]\n",
    "    k_t = xvals[:,1][1:100] \n",
    "    c_t = xvals[:,0][1:100]\n",
    "    c_t_1 = xvals[:,0][0:99]\n",
    "    w_t_1 = xvals[:,2][0:99]\n",
    "    m1 = (z_t - rho*z_t_1 - (1-rho)*mu).mean()\n",
    "    m2 = ((z_t - rho*z_t_1 - (1-rho)*mu)*z_t).mean()\n",
    "    m3 = (beta*alpha*np.exp(z_t)*k_t**(alpha-1)*c_t/c_t_1 - 1).mean()\n",
    "    m4 = ((beta*alpha*np.exp(z_t)*k_t**(alpha-1)*c_t/c_t_1 - 1)*w_t_1).mean()    \n",
    "    return m1, m2, m3, m4\n",
    "\n",
    "def err_vec2(alpha, beta, rho, mu, xvals):\n",
    "    m1, m2, m3, m4 = data_moment2(alpha, beta, rho, mu, xvals)\n",
    "    err_vec = np.array([m1, m2, m3, m4])\n",
    "    return err_vec.T\n",
    "\n",
    "def criterion2(params, *args):\n",
    "    alpha, beta, rho, mu = params\n",
    "    xvals,W = args\n",
    "    err = err_vec2(alpha, beta, rho, mu, xvals)\n",
    "    crit_val = err.T @ W @ err\n",
    "    return crit_val\n",
    "\n",
    "#Initial Values\n",
    "alpha_init2 = 0.30\n",
    "beta_init2 = 0.85\n",
    "rho_init2 = 0.85\n",
    "mu_init2 = 9.5\n",
    "\n",
    "#Identity Matrix\n",
    "W = np.eye(4)\n",
    "params_2 = np.array([alpha_init2, beta_init2, rho_init2, mu_init2])\n",
    "gmm2_arg= (pts2,W)\n",
    "result_2 = opt.minimize(criterion2, params_2, args = gmm2_arg, method = 'L-BFGS-B', bounds = ((1e-10, 1-1e-10),(1e-10, 1-1e-10),(-1+1e-10, 1-1e-10),(1e-10, None)))\n",
    "alpha_gmm2, beta_gmm2, rho_gmm2, mu_gmm2 = result_2.x\n",
    "\n",
    "#Result\n",
    "print(result_2)\n",
    "#Estimated Values\n",
    "print('alpha_GMM =', alpha_gmm2,'beta_GMM =',beta_gmm2, 'rho_GMM =',rho_gmm2, 'mu_GMM =',mu_gmm2)\n",
    "#Minimized Criterion Function\n",
    "print('Minimized Criterion Function =', result_2.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
